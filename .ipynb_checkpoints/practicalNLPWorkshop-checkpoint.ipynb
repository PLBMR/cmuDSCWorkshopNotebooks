{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tartan Data Science Club : Practical Natural Language Processing\n",
    "\n",
    "_By [Michael Rosenberg](mailto:mmrosenb@andrew.cmu.edu)._\n",
    "\n",
    "_**Description**: This notebook contains an introduction to document analysis with OkCupid data. It is designed to be used at a workshop for introducing individuals to natural language processing._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: What Is Natural Language Processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: WRITE OUT THIS PART**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note for 15-112 Students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: WRITE OUT THIS PART**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"metadataAnalysis\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: WRITE OUT THIS PART**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scanning a document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start by loading in the dataset of profiles. This is a ```.csv``` file, which stands for Comma-Separated Values. If we take a look at the [text representation of the dataset](data/JSE_OkCupid/profiles.csv), we see that there is a set of column keys in the first row of the ```.csv``` file, and each row below it refers to a filled-in observation of the dataset. In this context, a \"filled-in observation\" is a transcribed OkCupid profile.\n",
    "\n",
    "Typically, we can load in a ```.csv``` file using the ```csv``` package available in base ```Python```. However, for the sake of having a more elegant coding process, I generally use the ```pandas``` package to manipulative large dataframes. You can refer to the [reference materials](#refMaterials) for instructions on how to install ```pandas```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#read in a .csv file\n",
    "okCupidFrame = pd.read_csv(\"data/JSE_OkCupid/profiles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at the dimension of this data frame. This is held in the ```shape``` attribute of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numRows = okCupidFrame.shape[0]\n",
    "numCols = okCupidFrame.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "numCols": "31",
     "numRows": "59946"
    }
   },
   "source": [
    "We see that there are {{numRows}} profie observations in this dataset, which is a sizable amount of profiles to consider. We also see that each profile contains {{numCols}} features, many of which were transcribed by the original data collectors. As discussed in the [metadata analysis](#metadataAnalysis), the language-oriented features are found in the ```essay``` variables. For now, let us consider the self summary variable of the profiles contained in the ```essay0``` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selfSummaries = okCupidFrame[\"essay0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first check to see if there are any missing values in this column. This will be important for when we want to use these summaries for predictive purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make conditional on which summaries are empty\n",
    "emptySections = selfSummaries[selfSummaries.isnull()]\n",
    "numNullEntries = emptySections.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "numNullEntries": "5485"
    }
   },
   "source": [
    "We see that we have {{numNullEntries}} profiles without self-summaries. For the sake of considering only completed profiles up to the summary, we will filter out observations with ```NaN``` entries for ```essay0```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get observations with non-null summaries\n",
    "filteredOkCupidFrame = okCupidFrame[okCupidFrame[\"essay0\"].notnull()]\n",
    "#then reobtain self summaries\n",
    "selfSummaries = filteredOkCupidFrame[\"essay0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching and analyzing a single profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basis of natural language processing comes simply from analyzing a string. In this extent, it is natural to start out analysis by analyzing a single document, which in this case is a single self-summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consideredSummary = selfSummaries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a string, we can read it by a simple ```print``` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about me:<br />\n",
      "<br />\n",
      "i would love to think that i was some some kind of intellectual:\n",
      "either the dumbest smart guy, or the smartest dumb guy. can't say i\n",
      "can tell the difference. i love to talk about ideas and concepts. i\n",
      "forge odd metaphors instead of reciting cliches. like the\n",
      "simularities between a friend of mine's house and an underwater\n",
      "salt mine. my favorite word is salt by the way (weird choice i\n",
      "know). to me most things in life are better as metaphors. i seek to\n",
      "make myself a little better everyday, in some productively lazy\n",
      "way. got tired of tying my shoes. considered hiring a five year\n",
      "old, but would probably have to tie both of our shoes... decided to\n",
      "only wear leather shoes dress shoes.<br />\n",
      "<br />\n",
      "about you:<br />\n",
      "<br />\n",
      "you love to have really serious, really deep conversations about\n",
      "really silly stuff. you have to be willing to snap me out of a\n",
      "light hearted rant with a kiss. you don't have to be funny, but you\n",
      "have to be able to make me laugh. you should be able to bend spoons\n",
      "with your mind, and telepathically make me smile while i am still\n",
      "at work. you should love life, and be cool with just letting the\n",
      "wind blow. extra points for reading all this and guessing my\n",
      "favorite video game (no hints given yet). and lastly you have a\n",
      "good attention span.\n"
     ]
    }
   ],
   "source": [
    "print consideredSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 1: A self-summary of an individual in our dataset._\n",
    "\n",
    "We can see a couple of things just from looking at this profile:\n",
    "\n",
    "* This man sounds extremely pretentious.\n",
    "\n",
    "* There are some misspellings due to the user-inputted aspects in this self-summary. most notably, the word \"simularities\" should probably be \"similarities.\"\n",
    "\n",
    "* Ther are several ```br``` tags within the document that do not add information to our understanding of the document. These tags are primarily for OkCupid to display the self-summary properly on their website.\n",
    "\n",
    "Thus, before we analyze this dataset, we need to do some data cleansing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning and searching with Regular Expression (```regex```)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Regular Expression is defined as a sequence of characters that defines a search pattern. This search pattern is used to \"find\" and \"find and replace\" certain information in strings through string search algorithms. To give an example, say that I am interested in quantifying the narcissism found in the self-summary above. Perhaps I am interested in the number of times that \"i\" shows up in the summary. We represent this with the simple regular expression search query that accounts for the letter $i$ and then accounts for all potential punctuation that usually follows a lone $i$:\n",
    "\n",
    "```i[ \\.,:;?!\\n$]```\n",
    "\n",
    "This expression looks for $i$ and then looks for a potential followup punctuation to indicate that is a lone $i$. This can be a space, period, comma, colon, semi-colon, question mark, explanation point, or an end-of-line marker (```$```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re #regular expression library in base Python\n",
    "#let us compile this for search\n",
    "iRe = re.compile(\"i[ \\.,:?!\\n]\")\n",
    "#then find all the times it occurs in the summary\n",
    "iObservanceList = iRe.findall(consideredSummary)\n",
    "numIs = len(iObservanceList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "numIs": "8"
    }
   },
   "source": [
    "We see that the speaker refers to himself in terms of \"i\" {{numIs}} times in this self-summary. This is actually more reasonable than most people when referring to themselves, but let's try to extend this regular expression to other self-centered terms. We will now search for\n",
    "\n",
    "```(i|me)[ \\.,:?!\\n]```\n",
    "\n",
    "The ```|``` symbol represents an or operator for in a section. In this context, this regular expression is looking for either \"i\" or \"me\" followed by some punctuation in order to identify lone observations of ```i``` and ```me``` instead of appendages on other words (for example, ```i``` in ```intellectual``` and ```me``` in ```meandering```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selfCenteredRe = re.compile(\"(i|me)[ \\.,:?!\\n]\")\n",
    "#find all observations of this regular expression\n",
    "selfObsList = selfCenteredRe.findall(consideredSummary)\n",
    "#get length\n",
    "numNarcissisticWords = len(selfObsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "numNarcissisticWords": "17"
    }
   },
   "source": [
    "We see that when we extend our search to include \"me\" as a possible pattern to recognize, we see that the number of self-referrals increases to {{numNarcissisticWords}}. We can extend this to other aspects of the self-summary, and potentially more interesting patterns we want to find in the language.\n",
    "\n",
    "Regular Expressions can also be used to substitute particular components of the summary for data cleaning purposes. For instance, let us alter the mistake of \"simularities\" as \"similarities\" in the above summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about me:<br />\n",
      "<br />\n",
      "i would love to think that i was some some kind of intellectual:\n",
      "either the dumbest smart guy, or the smartest dumb guy. can't say i\n",
      "can tell the difference. i love to talk about ideas and concepts. i\n",
      "forge odd metaphors instead of reciting cliches. like the\n",
      "similarities between a friend of mine's house and an underwater\n",
      "salt mine. my favorite word is salt by the way (weird choice i\n",
      "know). to me most things in life are better as metaphors. i seek to\n",
      "make myself a little better everyday, in some productively lazy\n",
      "way. got tired of tying my shoes. considered hiring a five year\n",
      "old, but would probably have to tie both of our shoes... decided to\n",
      "only wear leather shoes dress shoes.<br />\n",
      "<br />\n",
      "about you:<br />\n",
      "<br />\n",
      "you love to have really serious, really deep conversations about\n",
      "really silly stuff. you have to be willing to snap me out of a\n",
      "light hearted rant with a kiss. you don't have to be funny, but you\n",
      "have to be able to make me laugh. you should be able to bend spoons\n",
      "with your mind, and telepathically make me smile while i am still\n",
      "at work. you should love life, and be cool with just letting the\n",
      "wind blow. extra points for reading all this and guessing my\n",
      "favorite video game (no hints given yet). and lastly you have a\n",
      "good attention span.\n"
     ]
    }
   ],
   "source": [
    "#make the re\n",
    "simRe = re.compile(\"simularities\")\n",
    "#then perform a sub\n",
    "filteredSummary = simRe.sub(\"similarities\",consideredSummary)\n",
    "print filteredSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 2: The filtered summary after changing the stated spelling issue._\n",
    "\n",
    "As we can see, \"simularities\" was changed to \"similarities\" without us having to find the exact beginning and ending indices for the \"simularities\" mistake. We can continue this cleaning by altering an even larger interpretation issue: the ```br``` tags. These tags are primarily used for OkCupid to understand how to display the text, but they generally are not informative to the summary itself.\n",
    "\n",
    "We will remove these by building the regular expression\n",
    "\n",
    "```<.*>```\n",
    "\n",
    "The ```.``` is meant to represent any character available in the ASCII encoding framework. the ```*``` is meant to represent \"0 or more observations of the prior character or expression.\" In this case, this regular expression is asking to find strings that start with \"<\" and end with \">\" and feature any number of characters in between \"<\" and \">.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about me:\n",
      "\n",
      "i would love to think that i was some some kind of intellectual:\n",
      "either the dumbest smart guy, or the smartest dumb guy. can't say i\n",
      "can tell the difference. i love to talk about ideas and concepts. i\n",
      "forge odd metaphors instead of reciting cliches. like the\n",
      "similarities between a friend of mine's house and an underwater\n",
      "salt mine. my favorite word is salt by the way (weird choice i\n",
      "know). to me most things in life are better as metaphors. i seek to\n",
      "make myself a little better everyday, in some productively lazy\n",
      "way. got tired of tying my shoes. considered hiring a five year\n",
      "old, but would probably have to tie both of our shoes... decided to\n",
      "only wear leather shoes dress shoes.\n",
      "\n",
      "about you:\n",
      "\n",
      "you love to have really serious, really deep conversations about\n",
      "really silly stuff. you have to be willing to snap me out of a\n",
      "light hearted rant with a kiss. you don't have to be funny, but you\n",
      "have to be able to make me laugh. you should be able to bend spoons\n",
      "with your mind, and telepathically make me smile while i am still\n",
      "at work. you should love life, and be cool with just letting the\n",
      "wind blow. extra points for reading all this and guessing my\n",
      "favorite video game (no hints given yet). and lastly you have a\n",
      "good attention span.\n"
     ]
    }
   ],
   "source": [
    "tagRe = re.compile(\"<.*>\")\n",
    "filteredSummary = tagRe.sub(\"\",filteredSummary)\n",
    "print filteredSummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 3: Our filtered summary after all ```br``` tags have been removed._\n",
    "\n",
    "As we can see, we have cleaned the summary to a point where there are no tags whatsoever in the text. We can then use this edited summary within the main dataset. This process is essentially a form of data cleansing with text.\n",
    "\n",
    "If you would like to learn more about ```regex```, see the links in the [reference materials](#refMaterials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: FINISH REGEX and WORD ANALYSIS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics on a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"refMaterials\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "605px",
   "left": "0px",
   "right": "auto",
   "top": "106px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
